# ML Layer 1 - Machine Learning Module

Complete ML prediction system with training (Python) and real-time inference (Rust).

## ğŸ“ Structure

```
ml-layer-1/
â”œâ”€â”€ training/          # Python: Train LSTM models
â”‚   â”œâ”€â”€ train.py
â”‚   â””â”€â”€ requirements.txt
â”œâ”€â”€ inference/         # Rust: Real-time inference â†’ writes to DB
â”‚   â”œâ”€â”€ src/main.rs
â”‚   â”œâ”€â”€ Cargo.toml
â”‚   â””â”€â”€ Dockerfile
â”œâ”€â”€ migrations/        # SQL: predictions tables
â”‚   â””â”€â”€ 001_ml_predictions.sql
â””â”€â”€ models/            # Generated by training
    â”œâ”€â”€ lstm_btc.onnx
    â”œâ”€â”€ normalization_params.json
    â””â”€â”€ model_metadata.json
```

## ğŸ”„ Data Flow

```
TimescaleDB (candles)
    â†“
training/train.py (Python)
    - Fetches candles from DB
    - Trains LSTM
    - Exports ONNX
    â†“
models/lstm_btc.onnx
    â†“
inference (Rust binary)
    - Runs ONNX inference every 60s
    - WRITES predictions to DB
    â†“
TimescaleDB (ml_predictions table)
    â†“
data-ws reads and streams
```

## ğŸš€ Quick Start

### 1. Apply Migrations

```bash
psql -h localhost -U mltrader -d btc_ml_production -f migrations/001_ml_predictions.sql
```

### 2. Train Model

```bash
cd training
pip3 install -r requirements.txt
python3 train.py
```

### 3. Deploy Inference

```bash
docker build -t ml-inference -f inference/Dockerfile .
docker run --gpus all -e DB_HOST=localhost ml-inference
```

## ğŸ“Š Predictions Table

```sql
SELECT time, current_price, predicted_15min, confidence_15min
FROM ml_predictions
ORDER BY time DESC
LIMIT 10;
```

## ğŸ¯ Key Features

- âœ… Training: Zero CSV files, direct DB access
- âœ… Inference: <10ms with TensorRT
- âœ… Writes predictions to TimescaleDB
- âœ… Separate data-ws service streams predictions
