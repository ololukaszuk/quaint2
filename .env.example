# ============================================================================
# BTC ML Production - Environment Configuration
# ============================================================================
# Copy this file to .env and update with your actual values
# IMPORTANT: Never commit .env with real passwords to version control
# ============================================================================

# ============================================================================
# DATABASE CONFIGURATION
# ============================================================================
DB_HOST=timescaledb
DB_PORT=5432
DB_NAME=btc_ml_production
DB_USER=mltrader
DB_PASSWORD=your_secure_password_here_change_this

# ============================================================================
# BINANCE API CONFIGURATION
# ============================================================================
# WebSocket endpoint for real-time price streaming
BINANCE_STREAM_URL=wss://stream.binance.com:9443/ws

# REST API endpoint for historical data backfill
BINANCE_API_URL=https://api.binance.com

# ============================================================================
# RUST DATA FEEDER SERVICE
# ============================================================================
FEEDER_PORT=8080
FEATURE_UPDATE_INTERVAL=60
GAP_DETECTION_THRESHOLD=70
LOG_LEVEL=info

# ============================================================================
# GO GAP HANDLER SERVICE
# ============================================================================
GAP_HANDLER_PORT=9000
MAX_CONCURRENT_BACKFILLS=5
BACKFILL_TIMEOUT_SECONDS=300

# ============================================================================
# PGADMIN CONFIGURATION
# ============================================================================
PGADMIN_PASSWORD=your_pgadmin_password_here_change_this
PGADMIN_PORT=8000

# ============================================================================
# ML LAYER 1 - TRAINING CONFIGURATION
# ============================================================================
TRAINING_MONTHS=12
MAMBA_EPOCHS=50

# ============================================================================
# ML LAYER 1 - INFERENCE CONFIGURATION
# ============================================================================
ML_ENABLED=true
ML_MAMBA_WEIGHT=0.5
ML_DEVICE=cuda
ML_INFERENCE_PORT=8081

# ============================================================================
# MARKET ANALYZER SERVICE
# ============================================================================
ANALYZER_PORT=8082
ANALYZER_POLL_INTERVAL=5
ANALYZER_LOOKBACK_CANDLES=300000
LLM_REQUESTS_ENABLED=true
DETAILED_LOGGING=false

# ============================================================================
# LLM ANALYST SERVICE (Ollama/DeepSeek)
# ============================================================================
# Full URL to Ollama API (can be local, docker, or remote)
OLLAMA_BASE_URL=http://localhost:11434

# Model to use (must be pulled in Ollama)
# Options: deepseek-r1:32b, deepseek-r1:latest, llama3:70b, etc.
OLLAMA_MODEL=deepseek-r1:32b

# Timeout for LLM requests (seconds) - reasoning models need more time
OLLAMA_TIMEOUT=300

# Run LLM analysis every N closed 1m candles
LLM_ANALYSIS_INTERVAL=5

# How many 1H candles to include in prompt (~5 days)
LLM_CANDLES_1H_LOOKBACK=120

# How many 15M candles to include (recent detail)
LLM_CANDLES_15M_LOOKBACK=20

# How many signal changes to include in context
LLM_SIGNAL_HISTORY=15

# Polling interval for new candles (seconds)
LLM_POLL_INTERVAL=10

# Service port
LLM_ANALYST_PORT=8083

# ============================================================================
# DATA API SERVICE (HTTPS REST API)
# ============================================================================
# API Key for authentication (REQUIRED - generate a strong random key)
# Generate with: openssl rand -base64 32
DATA_API_KEY=your_secure_api_key_here_change_this_minimum_32_chars

# Port for HTTPS API (default: 8443)
DATA_API_PORT=8443

# Enable/disable TLS (set to "false" for HTTP-only, not recommended)
DATA_API_USE_TLS=true

# Custom certificate paths (optional - uses self-signed if not specified)
# Uncomment and set these to use your own SSL certificates
# DATA_API_TLS_CERT_FILE=/certs/custom.crt
# DATA_API_TLS_KEY_FILE=/certs/custom.key

# ============================================================================
# GPU CONFIGURATION (RTX 5090 / CUDA 12.8)
# ============================================================================
CUDA_VISIBLE_DEVICES=0

# ============================================================================
# SECURITY & DEPLOYMENT
# ============================================================================
# Log level: debug, info, warn, error
LOG_LEVEL=info

# Environment: development, staging, production
ENVIRONMENT=production

# ============================================================================
# NOTES
# ============================================================================
# 1. All passwords AND API keys should be at least 20 characters (32+ recommended)
# 2. Use strong, unique passwords/keys for production
# 3. Never share .env file - add to .gitignore
# 4. Rotate passwords and API keys regularly
# 5. Use secrets management (vault, AWS Secrets Manager, etc.) in production
# 6. ML services require NVIDIA GPU with driver 550+ for CUDA 12.8
# 7. Install nvidia-container-toolkit for Docker GPU support
# 8. Data API uses self-signed certificates by default - see data-api/README.md
#    for instructions on using custom certificates in production
# 9. Generate API key with: openssl rand -base64 32
# 10. NEVER commit actual API keys to version control
